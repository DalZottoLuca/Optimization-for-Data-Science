# Optimization-for-Data-Science
Optimization for Data Science - Data Science Master Degree - Unipd

In this homework, three different techniques are considered to solve the regularized logistic regression problem. To be more specific, the task consists in comparing the performances of the classic gradient descent
method (GD) with fixed step-size, the stochastic gradient descent method (SGD) and the stochastic variance
reduced gradient method (SVRG). After having implemented them, they have to be tested on a publicly
available dataset, analyzing their accuracy vs the CPU time required by the computations.
